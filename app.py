import json
import os
import shutil
import tempfile
from datetime import datetime
from typing import List, Dict, Any, Optional

import aiofiles
import aiohttp
# åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆå¦‚æœæœ‰ï¼‰
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field

from agent.doc_detecter import detect_doc_type
from agent.extract_agent import extract_info
from agent.pdf_reader import pdf_text_reader

load_dotenv()
app = FastAPI(title="æ–‡æ¡£ä¿¡æ¯æå–æœåŠ¡", version="2.0.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


class ValidityCheckRequest(BaseModel):
    start_date: str = Field(..., description="èµ·å§‹æ—¥æœŸ (YYYY-MM-DD)")
    end_date: str = Field(..., description="ç»“æŸæ—¥æœŸ (YYYY-MM-DD)")
    docs: Dict[str, Dict[str, Dict[str, Any]]] = Field(..., description="å·²æå–çš„æ–‡æ¡£ç»“æ„åŒ–ä¿¡æ¯ï¼ŒåŒ…æ‹¬ä¸“åˆ©å’Œè®ºæ–‡")


class ValidityCheckResponse(BaseModel):
    valid_patents: List[Dict[str, Any]] = Field(..., description="æœ‰æ•ˆçš„ä¸“åˆ©æ–‡æ¡£")
    valid_papers: List[Dict[str, Any]] = Field(..., description="æœ‰æ•ˆçš„è®ºæ–‡æ–‡æ¡£")
    total_valid: int = Field(..., description="æœ‰æ•ˆæ–‡æ¡£æ€»æ•°")
    time_range: str = Field(..., description="æ—¶é—´èŒƒå›´")
    date_comparisons: List[Dict[str, Any]] = Field(..., description="æ—¥æœŸæ¯”è¾ƒç»“æœ")
    comparison_stats: Dict[str, Dict[str, int]] = Field(..., description="ç»Ÿè®¡ä¿¡æ¯")
    formatted_patent_results: List[str] = Field(..., description="ä¸“åˆ©çš„æ ¼å¼åŒ–ç»“æœ")
    formatted_paper_results: List[str] = Field(..., description="è®ºæ–‡çš„æ ¼å¼åŒ–ç»“æœ")


class ProcessResponse(BaseModel):
    results: Dict[str, str]  # æ¯ä¸ªæ–‡ä»¶çš„ç»“æœä»¥ id ä¸ºé”®
    data: Dict[str, dict]  # æ¯ä¸ªæ–‡ä»¶çš„ç»“æ„åŒ–æ•°æ®ä»¥ id ä¸ºé”®


async def download_from_url(url: str, save_path: str) -> bool:
    """ä¸‹è½½æ–‡ä»¶å¹¶æ˜¾ç¤ºè¿›åº¦ä¿¡æ¯"""
    try:
        print(f"â³ å¼€å§‹ä¸‹è½½: {url}")
        print(f"ğŸ“ ä¿å­˜è·¯å¾„: {save_path}")

        async with aiohttp.ClientSession() as session:
            async with session.get(url) as response:
                if response.status == 200:
                    # è·å–æ–‡ä»¶å¤§å°ï¼ˆå¯èƒ½ä¸å¯ç”¨ï¼‰
                    file_size = int(response.headers.get('content-length', 0))

                    # æ˜¾ç¤ºä¸‹è½½åŸºæœ¬ä¿¡æ¯
                    print(f"ğŸ“¦ æ–‡ä»¶å¤§å°: {file_size / 1024:.2f} KB" if file_size else "ğŸ“¦ æ–‡ä»¶å¤§å°: æœªçŸ¥")

                    content = b''
                    downloaded = 0
                    async for chunk in response.content.iter_chunked(1024 * 8):  # 8KB chunks
                        content += chunk
                        downloaded += len(chunk)

                        # æ˜¾ç¤ºä¸‹è½½è¿›åº¦ï¼ˆå¦‚æœæœ‰æ–‡ä»¶å¤§å°ä¿¡æ¯ï¼‰
                        if file_size > 0:
                            percent = downloaded / file_size * 100
                            print(f"â¬‡ï¸ ä¸‹è½½è¿›åº¦: {percent:.1f}% ({downloaded}/{file_size} bytes)", end='\r')

                    # ä¿å­˜æ–‡ä»¶
                    async with aiofiles.open(save_path, "wb") as f:
                        await f.write(content)

                    print(f"\nâœ… ä¸‹è½½å®Œæˆ: {url}")
                    return True

                print(f"âŒ ä¸‹è½½å¤±è´¥: HTTPçŠ¶æ€ç  {response.status}")
                return False

    except aiohttp.ClientError as e:
        print(f"âŒ ç½‘ç»œé”™è¯¯: {str(e)}")
    except IOError as e:
        print(f"âŒ æ–‡ä»¶ä¿å­˜é”™è¯¯: {str(e)}")
    except Exception as e:
        print(f"âŒ æœªçŸ¥é”™è¯¯: {str(e)}")

    return False


def parse_date(date_str: str) -> Optional[datetime]:
    formats = [
        "%Y-%m-%d", "%Y/%m/%d", "%Yå¹´%mæœˆ%dæ—¥",
        "%Y.%m.%d", "%d-%m-%Y", "%d/%m/%Y",
        "%b %d, %Y", "%B %d, %Y"
    ]
    for fmt in formats:
        try:
            return datetime.strptime(date_str, fmt)
        except ValueError:
            continue
    return None


def check_validity(item: dict, start_date: str, end_date: str) -> bool:
    try:
        start_dt = parse_date(start_date)
        end_dt = parse_date(end_date)
        if not all([start_dt, end_dt]):
            return False

        doc_type = item.get('ç±»å‹')

        # ä¸“åˆ©å¤„ç†é€»è¾‘
        if doc_type == 'ä¸“åˆ©':
            # ä¼˜å…ˆä½¿ç”¨æˆæƒæ—¥æœŸï¼Œè‹¥æ— åˆ™ä½¿ç”¨ç”³è¯·æ—¥æœŸ
            date_str = item.get('æˆæƒæ—¥æœŸ')
            if date_str in (None, 'N/A', ''):
                date_str = item.get('ç”³è¯·æ—¥æœŸ', 'N/A')

            # å¦‚æœä»ç„¶æ²¡æœ‰æœ‰æ•ˆæ—¥æœŸï¼Œåˆ™è·³è¿‡
            if date_str == 'N/A':
                return False

            doc_date = parse_date(date_str)
            return bool(doc_date and start_dt <= doc_date <= end_dt)

        # è®ºæ–‡å¤„ç†é€»è¾‘
        elif doc_type == 'è®ºæ–‡':
            year = item.get('å¹´ä»½')
            if not year or year == 'N/A':
                return False

            try:
                # å°†å¹´ä»½è½¬æ¢ä¸ºæ—¥æœŸï¼ˆå‡è®¾ä¸ºå½“å¹´1æœˆ1æ—¥ï¼‰
                doc_date = datetime(int(year), 1, 1)
                return start_dt <= doc_date <= end_dt
            except (ValueError, TypeError):
                return False

        # å…¶ä»–ç±»å‹æ–‡æ¡£
        return False

    except Exception as e:
        print(f"æ—¶æ•ˆæ£€æŸ¥é”™è¯¯: {e}")
        return False


@app.post("/api/v1/process_files", response_model=ProcessResponse)
async def process_files(files: List[UploadFile] = File(...)):
    temp_dir = tempfile.mkdtemp()
    results = {}
    structured_data = {}

    try:
        for idx, file in enumerate(files, start=1):
            file_id = f"id{idx}"
            temp_file_path = os.path.join(temp_dir, file.filename)
            url = None
            is_url = False

            # æ”¹è¿›çš„URLæ–‡ä»¶åˆ¤æ–­é€»è¾‘
            try:
                # æ–¹æ³•1ï¼šæ£€æŸ¥typeå±æ€§
                if getattr(file, 'type', None) == 'url':
                    is_url = True
                    url = getattr(file, 'url', '')

                # æ–¹æ³•2ï¼šæ£€æŸ¥æ–‡ä»¶å†…å®¹æ˜¯å¦ä¸ºJSONæ ¼å¼çš„URLä¿¡æ¯
                if not is_url:
                    content = await file.read()
                    try:
                        url_info = json.loads(content)
                        if isinstance(url_info, dict) and 'url' in url_info:
                            is_url = True
                            url = url_info['url']
                    except json.JSONDecodeError:
                        pass
                    await file.seek(0)  # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
            except Exception as e:
                pass

            # æ–‡ä»¶å†…å®¹è·å–é€»è¾‘
            try:
                if is_url and url:
                    print(f"ä¸‹è½½URLæ–‡ä»¶: {url}")
                    if not await download_from_url(url, temp_file_path):
                        # ä¿®æ”¹ä¸ºè¿”å›ç»“æ„åŒ–é”™è¯¯ä¿¡æ¯
                        raise HTTPException(
                            status_code=400,
                            detail={
                                "error": "URL_DOWNLOAD_FAILED",
                                "message": f"URLæ–‡ä»¶ä¸‹è½½å¤±è´¥: {url}",
                                "filename": file.filename,
                                "url": url,
                                "file_id": file_id
                            }
                        )

                else:
                    # æ™®é€šæ–‡ä»¶å¤„ç†
                    async with aiofiles.open(temp_file_path, "wb") as f:
                        await file.seek(0)
                        content = await file.read()
                        await f.write(content)
            except HTTPException as e:
                # ç›´æ¥é‡æ–°æŠ›å‡ºHTTPException
                raise e
            except Exception as e:
                raise HTTPException(
                    status_code=400,
                    detail={
                        "error": "FILE_PROCESSING_ERROR",
                        "message": str(e),
                        "filename": file.filename,
                        "file_id": file_id,
                        **({"url": url} if is_url else {})
                    }
                )

            # åç»­å¤„ç†ä¿æŒä¸å˜...
            text = await pdf_text_reader(temp_file_path)
            doc_type = await detect_doc_type(text)

            if doc_type == "ä¸“åˆ©":
                # æå–ä¸“åˆ©ä¿¡æ¯
                info = await extract_info(text, "ä¸“åˆ©")
                info.update({"æ–‡ä»¶å": file.filename, "ç±»å‹": "ä¸“åˆ©"})
                structured_data[file_id] = info
                result = f"æ–‡ä»¶: {file.filename}\nç±»å‹: ä¸“åˆ©\nä¸“åˆ©å·: {info.get('ä¸“åˆ©å·')}\nç”³è¯·æ—¥æœŸ: {info.get('ç”³è¯·æ—¥æœŸ')}\næˆæƒæ—¥æœŸ: {info.get('æˆæƒæ—¥æœŸ')}\nå‘æ˜äºº: {info.get('å‘æ˜äºº')}\nå—è®©äºº: {info.get('å—è®©äºº')}\n{'=' * 40}"

            elif doc_type == "è®ºæ–‡":
                # æå–è®ºæ–‡ä¿¡æ¯
                info = await extract_info(text, "è®ºæ–‡")
                info.update({"æ–‡ä»¶å": file.filename, "ç±»å‹": "è®ºæ–‡"})
                structured_data[file_id] = info
                result = f"""æ–‡ä»¶: {file.filename}
                        ç±»å‹: è®ºæ–‡
                        æ ‡é¢˜: {info.get('æ ‡é¢˜', 'N/A')}
                        ä½œè€…: {info.get('ä½œè€…', 'N/A')}
                        æœŸåˆŠ: {info.get('æœŸåˆŠ', 'N/A')}
                        å¹´ä»½: {str(info.get('year', 'N/A'))}
                        DOI: {info.get('DOI', 'N/A')}
                        æ”¶ç¨¿æ—¥æœŸ: {info.get('received_date', 'N/A')}
                        æ¥å—æ—¥æœŸ: {info.get('accepted_date', 'N/A')}
                        å‡ºç‰ˆæ—¥æœŸ: {info.get('published_date', 'N/A')}
                        {'=' * 40}"""
            else:
                # å¦‚æœä»æœªè¯†åˆ«ï¼Œåˆ™æ ‡è®°ä¸ºæœªè¯†åˆ«
                result = f"æ–‡ä»¶: {file.filename}\nç±»å‹: æœªè¯†åˆ«\n{'=' * 40}"
                structured_data[file_id] = {"æ–‡ä»¶å": file.filename, "ç±»å‹": "æœªè¯†åˆ«"}

            # ä¿å­˜ç»“æœ
            results[file_id] = result
    finally:
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        shutil.rmtree(temp_dir, ignore_errors=True)

    return ProcessResponse(results=results, data=structured_data)


@app.post("/api/v1/check_validity", response_model=ValidityCheckResponse)
async def check_documents_validity(request: ValidityCheckRequest):
    start_dt = parse_date(request.start_date)
    end_dt = parse_date(request.end_date)

    # éªŒè¯æ—¥æœŸæ ¼å¼
    if not all([start_dt, end_dt]):
        raise HTTPException(status_code=400, detail="æ—¥æœŸæ ¼å¼é”™è¯¯")
    if start_dt > end_dt:
        raise HTTPException(status_code=400, detail="èµ·å§‹æ—¥æœŸä¸èƒ½æ™šäºç»“æŸæ—¥æœŸ")

    # åˆå§‹åŒ–ç»“æœå­˜å‚¨
    valid_patents = []  # å­˜å‚¨æœ‰æ•ˆçš„ä¸“åˆ©æ–‡æ¡£
    valid_papers = []  # å­˜å‚¨æœ‰æ•ˆçš„è®ºæ–‡æ–‡æ¡£
    formatted_patent_results = []  # å­˜å‚¨ä¸“åˆ©çš„æ ¼å¼åŒ–ç»“æœ
    formatted_paper_results = []  # å­˜å‚¨è®ºæ–‡çš„æ ¼å¼åŒ–ç»“æœ
    date_comparisons = []  # å­˜å‚¨æ—¥æœŸæ¯”è¾ƒç»“æœ
    stats = {
        "patent": {"total": 0, "in_range": 0},
        "paper": {"total": 0, "in_range": 0}
    }

    # å¤„ç†ä¸“åˆ©æ•°æ®
    for patent_id, patent_doc in request.docs.get("patentData", {}).items():
        date_field = "ç”³è¯·æ—¥æœŸ"
        date_str = patent_doc.get(date_field, "")
        doc_date = parse_date(date_str) if date_str and date_str not in (None, 'N/A', '') else None

        stats["patent"]["total"] += 1

        if doc_date:
            in_range = start_dt <= doc_date <= end_dt
            date_comparisons.append({
                "filename": patent_doc.get("æ–‡ä»¶å", ""),
                "doc_type": "ä¸“åˆ©",
                "date_field": date_field,
                "date_value": date_str,
                "in_range": in_range
            })

            if in_range:
                valid_patents.append(patent_doc)  # æ·»åŠ åˆ°æœ‰æ•ˆä¸“åˆ©åˆ—è¡¨
                stats["patent"]["in_range"] += 1
                formatted = f"""ç±»å‹: ä¸“åˆ©
                                ä¸“åˆ©å·: {patent_doc.get('ä¸“åˆ©å·', 'N/A')}
                                ç”³è¯·æ—¥æœŸ: {patent_doc.get('ç”³è¯·æ—¥æœŸ', 'N/A')}
                                æˆæƒæ—¥æœŸ: {patent_doc.get('æˆæƒæ—¥æœŸ', 'N/A')}
                                å‘æ˜äºº: {patent_doc.get('å‘æ˜äºº', 'N/A')}
                                å—è®©äºº: {patent_doc.get('å—è®©äºº', 'N/A')}
                                æ–‡ä»¶å: {patent_doc.get('æ–‡ä»¶å', 'N/A')}
                                {'=' * 40}"""
                formatted_patent_results.append(formatted)

    # å¤„ç†è®ºæ–‡æ•°æ®
    for paper_id, paper_doc in request.docs.get("paperData", {}).items():
        date_field = "received_date"
        date_str = paper_doc.get(date_field, "")
        doc_date = parse_date(date_str) if date_str and date_str not in (None, 'N/A', '') else None

        stats["paper"]["total"] += 1

        if doc_date:
            in_range = start_dt <= doc_date <= end_dt
            date_comparisons.append({
                "filename": paper_doc.get("æ–‡ä»¶å", ""),
                "doc_type": "è®ºæ–‡",
                "date_field": date_field,
                "date_value": date_str,
                "in_range": in_range
            })

            if in_range:
                valid_papers.append(paper_doc)  # æ·»åŠ åˆ°æœ‰æ•ˆè®ºæ–‡åˆ—è¡¨
                stats["paper"]["in_range"] += 1
                formatted = f"""ç±»å‹: è®ºæ–‡
                                æ ‡é¢˜: {paper_doc.get('æ ‡é¢˜', 'N/A')}
                                ä½œè€…: {paper_doc.get('ä½œè€…', 'N/A')}
                                æœŸåˆŠ: {paper_doc.get('æœŸåˆŠ', 'N/A')}
                                å¹´ä»½: {str(paper_doc.get('year', 'N/A'))}
                                DOI: {paper_doc.get('DOI', 'N/A')}
                                æ”¶ç¨¿æ—¥æœŸ: {paper_doc.get('received_date', 'N/A')}
                                æ¥å—æ—¥æœŸ: {paper_doc.get('accepted_date', 'N/A')}
                                å‡ºç‰ˆæ—¥æœŸ: {paper_doc.get('published_date', 'N/A')}
                                æ–‡ä»¶å: {paper_doc.get('æ–‡ä»¶å', 'N/A')}
                                {'=' * 40}"""
                formatted_paper_results.append(formatted)

    return ValidityCheckResponse(
        valid_patents=valid_patents,
        valid_papers=valid_papers,
        total_valid=len(valid_patents) + len(valid_papers),
        time_range=f"{request.start_date} è‡³ {request.end_date}",
        date_comparisons=date_comparisons,
        comparison_stats=stats,
        formatted_patent_results=formatted_patent_results,
        formatted_paper_results=formatted_paper_results
    )


# å¯åŠ¨æœåŠ¡å™¨
if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8000)
