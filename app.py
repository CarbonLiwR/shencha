import json
import os
import shutil
import tempfile
from datetime import datetime
from typing import List, Dict, Any, Optional

import aiofiles
import aiohttp
# åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆå¦‚æœæœ‰ï¼‰
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field

from agent.doc_detecter import detect_doc_type
from agent.extract_agent import extract_info
from agent.pdf_reader import pdf_text_reader, pdf_pic_reader

load_dotenv()
app = FastAPI(title="æ–‡æ¡£ä¿¡æ¯æå–æœåŠ¡", version="2.0.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


class ValidityCheckRequest(BaseModel):
    start_date: str = Field(..., description="èµ·å§‹æ—¥æœŸ (YYYY-MM-DD)")
    end_date: str = Field(..., description="ç»“æŸæ—¥æœŸ (YYYY-MM-DD)")
    docs: Dict[str, Dict[str, Dict[str, Any]]] = Field(..., description="å·²æå–çš„æ–‡æ¡£ç»“æ„åŒ–ä¿¡æ¯ï¼ŒåŒ…æ‹¬ä¸“åˆ©å’Œè®ºæ–‡")


class ValidityCheckResponse(BaseModel):
    valid_patents: List[Dict[str, Any]] = Field(default_factory=list, description="æœ‰æ•ˆçš„ä¸“åˆ©æ–‡æ¡£")
    valid_papers: List[Dict[str, Any]] = Field(default_factory=list, description="æœ‰æ•ˆçš„è®ºæ–‡æ–‡æ¡£")
    valid_standards: List[Dict[str, Any]] = Field(default_factory=list, description="æœ‰æ•ˆçš„æ ‡å‡†æ–‡æ¡£")
    valid_copyrights: List[Dict[str, Any]] = Field(default_factory=list, description="æœ‰æ•ˆçš„è½¯ä»¶è‘—ä½œæƒæ–‡æ¡£")
    total_valid: int = Field(0, description="æœ‰æ•ˆæ–‡æ¡£æ€»æ•°")
    time_range: str = Field("", description="æ—¶é—´èŒƒå›´")
    date_comparisons: List[Dict[str, Any]] = Field(default_factory=list, description="æ—¥æœŸæ¯”è¾ƒç»“æœ")
    comparison_stats: Dict[str, Dict[str, int]] = Field(default_factory=dict, description="ç»Ÿè®¡ä¿¡æ¯")
    formatted_patent_results: List[str] = Field(default_factory=list, description="ä¸“åˆ©çš„æ ¼å¼åŒ–ç»“æœ")
    formatted_paper_results: List[str] = Field(default_factory=list, description="è®ºæ–‡çš„æ ¼å¼åŒ–ç»“æœ")
    formatted_standard_results: List[str] = Field(default_factory=list, description="æ ‡å‡†çš„æ ¼å¼åŒ–ç»“æœ")
    formatted_copyright_results: List[str] = Field(default_factory=list, description="è½¯è‘—çš„æ ¼å¼åŒ–ç»“æœ")

class ProcessResponse(BaseModel):
    results: Dict[str, str]  # æ¯ä¸ªæ–‡ä»¶çš„ç»“æœä»¥ id ä¸ºé”®
    data: Dict[str, dict]  # æ¯ä¸ªæ–‡ä»¶çš„ç»“æ„åŒ–æ•°æ®ä»¥ id ä¸ºé”®


async def download_from_url(url: str, save_path: str) -> bool:
    """ä¸‹è½½æ–‡ä»¶å¹¶æ˜¾ç¤ºè¿›åº¦ä¿¡æ¯"""
    try:
        print(f"â³ å¼€å§‹ä¸‹è½½: {url}")
        print(f"ğŸ“ ä¿å­˜è·¯å¾„: {save_path}")

        async with aiohttp.ClientSession() as session:
            async with session.get(url) as response:
                if response.status == 200:
                    # è·å–æ–‡ä»¶å¤§å°ï¼ˆå¯èƒ½ä¸å¯ç”¨ï¼‰
                    file_size = int(response.headers.get('content-length', 0))

                    # æ˜¾ç¤ºä¸‹è½½åŸºæœ¬ä¿¡æ¯
                    print(f"ğŸ“¦ æ–‡ä»¶å¤§å°: {file_size / 1024:.2f} KB" if file_size else "ğŸ“¦ æ–‡ä»¶å¤§å°: æœªçŸ¥")

                    content = b''
                    downloaded = 0
                    async for chunk in response.content.iter_chunked(1024 * 8):  # 8KB chunks
                        content += chunk
                        downloaded += len(chunk)

                        # æ˜¾ç¤ºä¸‹è½½è¿›åº¦ï¼ˆå¦‚æœæœ‰æ–‡ä»¶å¤§å°ä¿¡æ¯ï¼‰
                        if file_size > 0:
                            percent = downloaded / file_size * 100
                            print(f"â¬‡ï¸ ä¸‹è½½è¿›åº¦: {percent:.1f}% ({downloaded}/{file_size} bytes)", end='\r')

                    # ä¿å­˜æ–‡ä»¶
                    async with aiofiles.open(save_path, "wb") as f:
                        await f.write(content)

                    print(f"\nâœ… ä¸‹è½½å®Œæˆ: {url}")
                    return True

                print(f"âŒ ä¸‹è½½å¤±è´¥: HTTPçŠ¶æ€ç  {response.status}")
                return False

    except aiohttp.ClientError as e:
        print(f"âŒ ç½‘ç»œé”™è¯¯: {str(e)}")
    except IOError as e:
        print(f"âŒ æ–‡ä»¶ä¿å­˜é”™è¯¯: {str(e)}")
    except Exception as e:
        print(f"âŒ æœªçŸ¥é”™è¯¯: {str(e)}")

    return False


def parse_date(date_str: str) -> Optional[datetime]:
    formats = [
        "%Y-%m-%d", "%Y/%m/%d", "%Yå¹´%mæœˆ%dæ—¥",
        "%Y.%m.%d", "%d-%m-%Y", "%d/%m/%Y",
        "%b %d, %Y", "%B %d, %Y"
    ]
    for fmt in formats:
        try:
            return datetime.strptime(date_str, fmt)
        except ValueError:
            continue
    return None


def check_validity(item: dict, start_date: str, end_date: str) -> bool:
    try:
        start_dt = parse_date(start_date)
        end_dt = parse_date(end_date)
        if not all([start_dt, end_dt]):
            return False

        doc_type = item.get('ç±»å‹')

        # ä¸“åˆ©å¤„ç†é€»è¾‘
        if "ä¸“åˆ©" in doc_type:
            # ä¼˜å…ˆä½¿ç”¨æˆæƒæ—¥æœŸï¼Œè‹¥æ— åˆ™ä½¿ç”¨ç”³è¯·æ—¥æœŸ
            date_str = item.get('æˆæƒæ—¥æœŸ')
            if date_str in (None, 'N/A', ''):
                date_str = item.get('ç”³è¯·æ—¥æœŸ', 'N/A')

            # å¦‚æœä»ç„¶æ²¡æœ‰æœ‰æ•ˆæ—¥æœŸï¼Œåˆ™è·³è¿‡
            if date_str == 'N/A':
                return False

            doc_date = parse_date(date_str)
            return bool(doc_date and start_dt <= doc_date <= end_dt)

        # è®ºæ–‡å¤„ç†é€»è¾‘
        elif 'è®ºæ–‡' in doc_type :
            year = item.get('å¹´ä»½')
            if not year or year == 'N/A':
                return False

            try:
                # å°†å¹´ä»½è½¬æ¢ä¸ºæ—¥æœŸï¼ˆå‡è®¾ä¸ºå½“å¹´1æœˆ1æ—¥ï¼‰
                doc_date = datetime(int(year), 1, 1)
                return start_dt <= doc_date <= end_dt
            except (ValueError, TypeError):
                return False

        # æ ‡å‡†å¤„ç†é€»è¾‘
        elif 'æ ‡å‡†' in doc_type:
            # ä¼˜å…ˆä½¿ç”¨å‘å¸ƒæ—¶é—´ï¼Œè‹¥æ— åˆ™ä½¿ç”¨å®æ–½æ—¶é—´
            date_str = item.get('å‘å¸ƒæ—¶é—´')
            if date_str in (None, 'N/A', ''):
                date_str = item.get('å®æ–½æ—¶é—´', 'N/A')

            # å¦‚æœä»ç„¶æ²¡æœ‰æœ‰æ•ˆæ—¥æœŸï¼Œåˆ™è·³è¿‡
            if date_str == 'N/A':
                return False

            doc_date = parse_date(date_str)
            return bool(doc_date and start_dt <= doc_date <= end_dt)

        # è½¯è‘—å¤„ç†é€»è¾‘
        elif 'è½¯è‘—' in doc_type:
            date_str = item.get('æˆæƒæ—¶é—´')
            if date_str in (None, 'N/A', ''):
                return False

            doc_date = parse_date(date_str)
            return bool(doc_date and start_dt <= doc_date <= end_dt)

        # å…¶ä»–ç±»å‹æ–‡æ¡£
        return False

    except Exception as e:
        print(f"æ—¶æ•ˆæ£€æŸ¥é”™è¯¯: {e}")
        return False


@app.post("/api/v1/process_files", response_model=ProcessResponse)
async def process_files(files: List[UploadFile] = File(...)):
    temp_dir = tempfile.mkdtemp()
    results = {}
    structured_data = {}

    try:
        for idx, file in enumerate(files, start=1):
            file_id = f"id{idx}"
            temp_file_path = os.path.join(temp_dir, file.filename)
            url = None
            is_url = False

            # æ”¹è¿›çš„URLæ–‡ä»¶åˆ¤æ–­é€»è¾‘
            try:
                # æ–¹æ³•1ï¼šæ£€æŸ¥typeå±æ€§
                if getattr(file, 'type', None) == 'url':
                    is_url = True
                    url = getattr(file, 'url', '')

                # æ–¹æ³•2ï¼šæ£€æŸ¥æ–‡ä»¶å†…å®¹æ˜¯å¦ä¸ºJSONæ ¼å¼çš„URLä¿¡æ¯
                if not is_url:
                    content = await file.read()
                    try:
                        url_info = json.loads(content)
                        if isinstance(url_info, dict) and 'url' in url_info:
                            is_url = True
                            url = url_info['url']
                    except json.JSONDecodeError:
                        pass
                    await file.seek(0)  # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
            except Exception as e:
                pass

            # æ–‡ä»¶å†…å®¹è·å–é€»è¾‘
            try:
                if is_url and url:
                    print(f"ä¸‹è½½URLæ–‡ä»¶: {url}")
                    if not await download_from_url(url, temp_file_path):
                        # ä¿®æ”¹ä¸ºè¿”å›ç»“æ„åŒ–é”™è¯¯ä¿¡æ¯
                        raise HTTPException(
                            status_code=400,
                            detail={
                                "error": "URL_DOWNLOAD_FAILED",
                                "message": f"URLæ–‡ä»¶ä¸‹è½½å¤±è´¥: {url}",
                                "filename": file.filename,
                                "url": url,
                                "file_id": file_id
                            }
                        )

                else:
                    # æ™®é€šæ–‡ä»¶å¤„ç†
                    async with aiofiles.open(temp_file_path, "wb") as f:
                        await file.seek(0)
                        content = await file.read()
                        await f.write(content)
            except HTTPException as e:
                # ç›´æ¥é‡æ–°æŠ›å‡ºHTTPException
                raise e
            except Exception as e:
                raise HTTPException(
                    status_code=400,
                    detail={
                        "error": "FILE_PROCESSING_ERROR",
                        "message": str(e),
                        "filename": file.filename,
                        "file_id": file_id,
                        **({"url": url} if is_url else {})
                    }
                )

            # åç»­å¤„ç†ä¿æŒä¸å˜...
            text = await pdf_text_reader(temp_file_path)
            raw_doc_type = await detect_doc_type(text)
            # å¤„ç†doc_typeï¼Œåªä¿ç•™</think>åçš„å†…å®¹
            print("å¤§æ¨¡å‹",raw_doc_type)
            doc_type = raw_doc_type.split("</think>")[-1].strip()
            print(f"æ£€æµ‹åˆ°çš„æ–‡æ¡£ç±»å‹111: {doc_type}")
            print("111", text[:12000])
            print("111", text[-12000:])
            

            if "ä¸“åˆ©" in doc_type:
                # æå–ä¸“åˆ©ä¿¡æ¯

                info = await extract_info(text, "ä¸“åˆ©", file.filename)
                info.update({"æ–‡ä»¶å": file.filename, "ç±»å‹": "ä¸“åˆ©"})
                structured_data[file_id] = info
                result = f"æ–‡ä»¶: {file.filename}\nç±»å‹: ä¸“åˆ©\nä¸“åˆ©å·ï¼š{info.get('ä¸“åˆ©å·')}\nä¸“åˆ©åç§°: {info.get('ä¸“åˆ©åç§°')}\nç”³è¯·æ—¥æœŸ: {info.get('ç”³è¯·æ—¥æœŸ')}\næˆæƒæ—¥æœŸ: {info.get('æˆæƒæ—¥æœŸ')}\nå‘æ˜äºº: {info.get('å‘æ˜äºº')}\nå—è®©äºº: {info.get('å—è®©äºº')}\n{'=' * 40}"

            elif "è®ºæ–‡" in doc_type:
                # æå–è®ºæ–‡ä¿¡æ¯
                info = await extract_info(text, "è®ºæ–‡", file.filename)
                info.update({"æ–‡ä»¶å": file.filename, "ç±»å‹": "è®ºæ–‡"})
                structured_data[file_id] = info
                result = f"""æ–‡ä»¶: {file.filename}
                        ç±»å‹: è®ºæ–‡
                        æ ‡é¢˜: {info.get('æ ‡é¢˜', 'N/A')}
                        ä½œè€…: {info.get('ä½œè€…', 'N/A')}
                        æœŸåˆŠ: {info.get('æœŸåˆŠ', 'N/A')}
                        å¹´ä»½: {str(info.get('year', 'N/A'))}
                        DOI: {info.get('DOI', 'N/A')}
                        æ”¶ç¨¿æ—¥æœŸ: {info.get('received_date', 'N/A')}
                        æ¥å—æ—¥æœŸ: {info.get('accepted_date', 'N/A')}
                        å‡ºç‰ˆæ—¥æœŸ: {info.get('published_date', 'N/A')}
                        é¡¹ç›®ç¼–å·: {info.get('project_number', 'N/A')} 
                        å•ä½: {info.get('institution', 'N/A')}    
                        {'=' * 40}"""

            elif "æ ‡å‡†" in doc_type:
                # æå–æ ‡å‡†ä¿¡æ¯
                info = await extract_info(text, "æ ‡å‡†", file.filename)
                info.update({"æ–‡ä»¶å": file.filename, "ç±»å‹": "æ ‡å‡†"})
                structured_data[file_id] = info
                result = f"""æ–‡ä»¶: {file.filename}
                        ç±»å‹: æ ‡å‡†
                        æ ‡å‡†åç§°: {info.get('æ ‡å‡†åç§°', 'N/A')}
                        æ ‡å‡†å½¢å¼: {info.get('æ ‡å‡†å½¢å¼', 'N/A')}
                        æ ‡å‡†ç¼–å·: {info.get('æ ‡å‡†ç¼–å·', 'N/A')}
                        èµ·è‰å•ä½: {info.get('èµ·è‰å•ä½', 'N/A')}
                        èµ·è‰äºº: {info.get('èµ·è‰äºº', 'N/A')}
                        å‘å¸ƒå•ä½: {info.get('å‘å¸ƒå•ä½', 'N/A')}
                        å‘å¸ƒæ—¶é—´: {info.get('å‘å¸ƒæ—¶é—´', 'N/A')}
                        å®æ–½æ—¶é—´: {info.get('å®æ–½æ—¶é—´', 'N/A')}
                        {'=' * 40}"""

            elif "è½¯è‘—" in doc_type:
                # æå–è½¯è‘—ä¿¡æ¯
                info = await extract_info(text, "è½¯è‘—", file.filename)
                info.update({"æ–‡ä»¶å": file.filename, "ç±»å‹": "è½¯è‘—"})
                structured_data[file_id] = info
                result = f"""æ–‡ä»¶: {file.filename}
                        ç±»å‹: è½¯è‘—
                        è¯ä¹¦å·: {info.get('è¯ä¹¦å·', 'N/A')}
                        è½¯ä»¶åç§°: {info.get('è½¯ä»¶åç§°', 'N/A')}
                        è‘—ä½œæƒäºº: {info.get('è‘—ä½œæƒäºº', 'N/A')}
                        ç™»è®°å·: {info.get('ç™»è®°å·', 'N/A')}
                        æˆæƒæ—¶é—´: {info.get('æˆæƒæ—¶é—´', 'N/A')}
                        {'=' * 40}"""
            else:
                # ç±»å‹æœªè¯†åˆ«ï¼Œè°ƒç”¨ pdf_pic_reader æå–æ–‡æœ¬
                print(f"æœªè¯†åˆ«çš„æ–‡æ¡£ç±»å‹ï¼Œå°è¯•é€šè¿‡å›¾ç‰‡æå–æ–‡æœ¬: {file.filename}")
                try:
                    text = await pdf_pic_reader(temp_file_path)  # ä¿®æ”¹ä¸ºç›´æ¥å¤„ç†ä¸´æ—¶æ–‡ä»¶è·¯å¾„
                except Exception as e:
                    print(f"PDF è½¬å›¾ç‰‡å¤±è´¥: {e}")
                    text = None
                print(f"é‡æ–°æ£€æµ‹çš„æ–‡æœ¬å†…å®¹: {text[:12000] if text else 'æ— æ–‡æœ¬'}")
                # é‡æ–°æ£€æµ‹æ–‡æ¡£ç±»å‹
                raw_doc_type = await detect_doc_type(text)if text else "å…¶ä»–"
                # å¤„ç†doc_typeï¼Œåªä¿ç•™</think>åçš„å†…å®¹
                doc_type = raw_doc_type.split("</think>")[-1].strip()

                print("é‡æ–°æ£€æµ‹çš„ doc_type", doc_type)

                if "ä¸“åˆ©" in doc_type:
                    # æå–ä¸“åˆ©ä¿¡æ¯
                    info = await extract_info(text, "ä¸“åˆ©", file.filename)
                    info.update({"æ–‡ä»¶å": file.filename, "ç±»å‹": "ä¸“åˆ©"})
                    structured_data[file_id] = info
                    result = f"æ–‡ä»¶: {file.filename}\nç±»å‹: ä¸“åˆ©\nä¸“åˆ©å·: {info.get('ä¸“åˆ©å·')}\nä¸“åˆ©åç§°: {info.get('ä¸“åˆ©åç§°')}\nç”³è¯·æ—¥æœŸ: {info.get('ç”³è¯·æ—¥æœŸ')}\næˆæƒæ—¥æœŸ: {info.get('æˆæƒæ—¥æœŸ')}\nå‘æ˜äºº: {info.get('å‘æ˜äºº')}\nå—è®©äºº: {info.get('å—è®©äºº')}\n{'=' * 40}"

                elif "è®ºæ–‡" in doc_type:
                    # æå–è®ºæ–‡ä¿¡æ¯
                    info = await extract_info(text, "è®ºæ–‡", file.filename)
                    info.update({"æ–‡ä»¶å": file.filename, "ç±»å‹": "è®ºæ–‡"})
                    structured_data[file_id] = info
                    result = f"""æ–‡ä»¶: {file.filename}
                                            ç±»å‹: è®ºæ–‡
                                            æ ‡é¢˜: {info.get('æ ‡é¢˜', 'N/A')}
                                            ä½œè€…: {info.get('ä½œè€…', 'N/A')}
                                            æœŸåˆŠ: {info.get('æœŸåˆŠ', 'N/A')}
                                            å¹´ä»½: {str(info.get('year', 'N/A'))}
                                            DOI: {info.get('DOI', 'N/A')}
                                            æ”¶ç¨¿æ—¥æœŸ: {info.get('received_date', 'N/A')}
                                            æ¥å—æ—¥æœŸ: {info.get('accepted_date', 'N/A')}
                                            å‡ºç‰ˆæ—¥æœŸ: {info.get('published_date', 'N/A')}
                                            é¡¹ç›®ç¼–å·: {info.get('project_number', 'N/A')} 
                                            å•ä½: {info.get('institution', 'N/A')} 
                                            {'=' * 40}"""

                elif "æ ‡å‡†" in doc_type:
                    # æå–æ ‡å‡†ä¿¡æ¯
                    info = await extract_info(text, "æ ‡å‡†", file.filename)
                    info.update({"æ–‡ä»¶å": file.filename, "ç±»å‹": "æ ‡å‡†"})
                    structured_data[file_id] = info
                    result = f"""æ–‡ä»¶: {file.filename}
                            ç±»å‹: æ ‡å‡†
                            æ ‡å‡†åç§°: {info.get('æ ‡å‡†åç§°', 'N/A')}
                            æ ‡å‡†å½¢å¼: {info.get('æ ‡å‡†å½¢å¼', 'N/A')}
                            æ ‡å‡†ç¼–å·: {info.get('æ ‡å‡†ç¼–å·', 'N/A')}
                            èµ·è‰å•ä½: {info.get('èµ·è‰å•ä½', 'N/A')}
                            èµ·è‰äºº: {info.get('èµ·è‰äºº', 'N/A')}
                            å‘å¸ƒå•ä½: {info.get('å‘å¸ƒå•ä½', 'N/A')}
                            å‘å¸ƒæ—¶é—´: {info.get('å‘å¸ƒæ—¶é—´', 'N/A')}
                            å®æ–½æ—¶é—´: {info.get('å®æ–½æ—¶é—´', 'N/A')}
                            {'=' * 40}"""

                elif "è½¯è‘—" in doc_type :
                    # æå–æ ‡å‡†ä¿¡æ¯
                    info = await extract_info(text, "è½¯è‘—", file.filename)
                    info.update({"æ–‡ä»¶å": file.filename, "ç±»å‹": "è½¯è‘—"})
                    structured_data[file_id] = info
                    result = f"""æ–‡ä»¶: {file.filename}
                            ç±»å‹: è½¯è‘—
                            è¯ä¹¦å·: {info.get('è¯ä¹¦å·', 'N/A')}
                            è½¯ä»¶åç§°: {info.get('è½¯ä»¶åç§°', 'N/A')}
                            è‘—ä½œæƒäºº: {info.get('è‘—ä½œæƒäºº', 'N/A')}
                            ç™»è®°å·: {info.get('ç™»è®°å·', 'N/A')}
                            æˆæƒæ—¶é—´: {info.get('æˆæƒæ—¶é—´', 'N/A')}
                            {'=' * 40}"""

                else:
                    # å¦‚æœä»æœªè¯†åˆ«ï¼Œåˆ™æ ‡è®°ä¸ºæœªè¯†åˆ«
                    result = f"æ–‡ä»¶: {file.filename}\nç±»å‹: æœªè¯†åˆ«\n{'=' * 40}"
                    structured_data[file_id] = {"æ–‡ä»¶å": file.filename, "ç±»å‹": "æœªè¯†åˆ«"}
            print("result1",result)
            # ä¿å­˜ç»“æœ
            results[file_id] = result
    finally:
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        shutil.rmtree(temp_dir, ignore_errors=True)

    return ProcessResponse(results=results, data=structured_data)


@app.post("/api/v1/check_validity", response_model=ValidityCheckResponse)
async def check_documents_validity(request: ValidityCheckRequest):
    start_dt = parse_date(request.start_date)
    end_dt = parse_date(request.end_date)

    # éªŒè¯æ—¥æœŸæ ¼å¼
    if not all([start_dt, end_dt]):
        raise HTTPException(status_code=400, detail="æ—¥æœŸæ ¼å¼é”™è¯¯")
    if start_dt > end_dt:
        raise HTTPException(status_code=400, detail="èµ·å§‹æ—¥æœŸä¸èƒ½æ™šäºç»“æŸæ—¥æœŸ")

    # åˆå§‹åŒ–ç»“æœå­˜å‚¨
    valid_patents = []  # å­˜å‚¨æœ‰æ•ˆçš„ä¸“åˆ©æ–‡æ¡£
    valid_papers = []  # å­˜å‚¨æœ‰æ•ˆçš„è®ºæ–‡æ–‡æ¡£
    valid_standards = [] # å­˜å‚¨æœ‰æ•ˆçš„æ ‡å‡†æ–‡æ¡£
    valid_copyrights = []  # å­˜å‚¨æœ‰æ•ˆçš„è½¯è‘—æ–‡æ¡£
    formatted_patent_results = []  # å­˜å‚¨ä¸“åˆ©çš„æ ¼å¼åŒ–ç»“æœ
    formatted_paper_results = []  # å­˜å‚¨è®ºæ–‡çš„æ ¼å¼åŒ–ç»“æœ
    formatted_standard_results = []  # å­˜å‚¨æ ‡å‡†çš„æ ¼å¼åŒ–ç»“æœ
    formatted_copyright_results = []  # å­˜å‚¨è½¯è‘—çš„æ ¼å¼åŒ–ç»“æœ
    date_comparisons = []  # å­˜å‚¨æ—¥æœŸæ¯”è¾ƒç»“æœ
    stats = {
        "patent": {"total": 0, "in_range": 0},
        "paper": {"total": 0, "in_range": 0},
        "standard": {"total": 0, "in_range": 0},
        "copyright": {"total": 0, "in_range": 0}
    }

    # å¤„ç†ä¸“åˆ©æ•°æ®
    for patent_id, patent_doc in request.docs.get("patentData", {}).items():
        date_field = "ç”³è¯·æ—¥æœŸ"
        date_str = patent_doc.get(date_field, "")
        doc_date = parse_date(date_str) if date_str and date_str not in (None, 'N/A', '') else None

        stats["patent"]["total"] += 1

        if doc_date:
            in_range = start_dt <= doc_date <= end_dt
            date_comparisons.append({
                "filename": patent_doc.get("æ–‡ä»¶å", ""),
                "doc_type": "ä¸“åˆ©",
                "date_field": date_field,
                "date_value": date_str,
                "in_range": in_range
            })

            if in_range:
                valid_patents.append(patent_doc)  # æ·»åŠ åˆ°æœ‰æ•ˆä¸“åˆ©åˆ—è¡¨
                stats["patent"]["in_range"] += 1
                formatted = f"""ç±»å‹: ä¸“åˆ©
                                ä¸“åˆ©åç§°: {patent_doc.get('ä¸“åˆ©åç§°', 'N/A')}
                                ç”³è¯·æ—¥æœŸ: {patent_doc.get('ç”³è¯·æ—¥æœŸ', 'N/A')}
                                æˆæƒæ—¥æœŸ: {patent_doc.get('æˆæƒæ—¥æœŸ', 'N/A')}
                                å‘æ˜äºº: {patent_doc.get('å‘æ˜äºº', 'N/A')}
                                å—è®©äºº: {patent_doc.get('å—è®©äºº', 'N/A')}
                                æ–‡ä»¶å: {patent_doc.get('æ–‡ä»¶å', 'N/A')}
                                {'=' * 40}"""
                formatted_patent_results.append(formatted)

    # å¤„ç†è®ºæ–‡æ•°æ®
    for paper_id, paper_doc in request.docs.get("paperData", {}).items():
        date_field = "received_date"
        date_str = paper_doc.get(date_field, "")
        doc_date = parse_date(date_str) if date_str and date_str not in (None, 'N/A', '') else None

        stats["paper"]["total"] += 1

        if doc_date:
            in_range = start_dt <= doc_date <= end_dt
            date_comparisons.append({
                "filename": paper_doc.get("æ–‡ä»¶å", ""),
                "doc_type": "è®ºæ–‡",
                "date_field": date_field,
                "date_value": date_str,
                "in_range": in_range
            })

            if in_range:
                valid_papers.append(paper_doc)  # æ·»åŠ åˆ°æœ‰æ•ˆè®ºæ–‡åˆ—è¡¨
                stats["paper"]["in_range"] += 1
                formatted = f"""ç±»å‹: è®ºæ–‡
                                æ ‡é¢˜: {paper_doc.get('æ ‡é¢˜', 'N/A')}
                                ä½œè€…: {paper_doc.get('ä½œè€…', 'N/A')}
                                æœŸåˆŠ: {paper_doc.get('æœŸåˆŠ', 'N/A')}
                                å¹´ä»½: {str(paper_doc.get('year', 'N/A'))}
                                DOI: {paper_doc.get('DOI', 'N/A')}
                                æ”¶ç¨¿æ—¥æœŸ: {paper_doc.get('received_date', 'N/A')}
                                æ¥å—æ—¥æœŸ: {paper_doc.get('accepted_date', 'N/A')}
                                å‡ºç‰ˆæ—¥æœŸ: {paper_doc.get('published_date', 'N/A')}
                                é¡¹ç›®ç¼–å·: {paper_doc.get('project_number', 'N/A')}  # æ–°å¢è¡Œ
                                å•ä½: {paper_doc.get('institution', 'N/A')}  # æ–°å¢è¡Œ
                                æ–‡ä»¶å: {paper_doc.get('æ–‡ä»¶å', 'N/A')}
                                {'=' * 40}"""
                formatted_paper_results.append(formatted)

    for standard_id, standard_doc in request.docs.get("standardData", {}).items():
        date_field = "å‘å¸ƒæ—¶é—´"
        date_str = standard_doc.get(date_field, "")
        doc_date = parse_date(date_str) if date_str and date_str not in (None, 'N/A', '') else None

        stats["standard"]["total"] += 1

        if doc_date:
            in_range = start_dt <= doc_date <= end_dt
            date_comparisons.append({
                "filename": standard_doc.get("æ–‡ä»¶å", ""),
                "doc_type": "æ ‡å‡†",
                "date_field": date_field,
                "date_value": date_str,
                "in_range": in_range
            })

            if in_range:
                valid_standards.append(standard_doc)
                stats["standard"]["in_range"] += 1
                formatted = f"""ç±»å‹: æ ‡å‡†
                                æ ‡å‡†åç§°: {standard_doc.get('æ ‡å‡†åç§°', 'N/A')}
                                æ ‡å‡†å½¢å¼: {standard_doc.get('æ ‡å‡†å½¢å¼', 'N/A')}
                                æ ‡å‡†ç¼–å·: {standard_doc.get('æ ‡å‡†ç¼–å·', 'N/A')}
                                å‘å¸ƒå•ä½: {standard_doc.get('å‘å¸ƒå•ä½', 'N/A')}
                                å‘å¸ƒæ—¶é—´: {standard_doc.get('å‘å¸ƒæ—¶é—´', 'N/A')}
                                å®æ–½æ—¶é—´: {standard_doc.get('å®æ–½æ—¶é—´', 'N/A')}
                                æ–‡ä»¶å: {standard_doc.get('æ–‡ä»¶å', 'N/A')}
                                {'=' * 40}"""
                formatted_standard_results.append(formatted)

    # å¤„ç†è½¯è‘—æ•°æ®
    for copyright_id, copyright_doc in request.docs.get("copyrightData", {}).items():
        date_field = "æˆæƒæ—¶é—´"
        date_str = copyright_doc.get(date_field, "")
        doc_date = parse_date(date_str) if date_str and date_str not in (None, 'N/A', '') else None

        stats["copyright"] = stats.get("copyright", {"total": 0, "in_range": 0})
        stats["copyright"]["total"] += 1

        if doc_date:
            in_range = start_dt <= doc_date <= end_dt
            date_comparisons.append({
                "filename": copyright_doc.get("æ–‡ä»¶å", ""),
                "doc_type": "è½¯è‘—",
                "date_field": date_field,
                "date_value": date_str,
                "in_range": in_range
            })

            if in_range:
                valid_copyrights.append(copyright_doc)
                stats["copyright"]["in_range"] += 1
                formatted = f"""ç±»å‹: è½¯è‘—
                                è¯ä¹¦å·: {copyright_doc.get('è¯ä¹¦å·', 'N/A')}
                                è½¯ä»¶åç§°: {copyright_doc.get('è½¯ä»¶åç§°', 'N/A')}
                                è‘—ä½œæƒäºº: {copyright_doc.get('è‘—ä½œæƒäºº', 'N/A')}
                                ç™»è®°å·: {copyright_doc.get('ç™»è®°å·', 'N/A')}
                                æˆæƒæ—¶é—´: {copyright_doc.get('æˆæƒæ—¶é—´', 'N/A')}
                                æ–‡ä»¶å: {copyright_doc.get('æ–‡ä»¶å', 'N/A')}
                                {'=' * 40}"""
                formatted_copyright_results.append(formatted)

    return ValidityCheckResponse(
        valid_patents=valid_patents,
        valid_papers=valid_papers,
        valid_standards=valid_standards,  # ç¡®ä¿åŒ…å«æ­¤å­—æ®µ
        valid_copyrights=valid_copyrights,
        total_valid=len(valid_patents) + len(valid_papers) + len(valid_standards)+ len(valid_copyrights),  # æ›´æ–°æ€»æ•°è®¡ç®—
        time_range=f"{request.start_date} è‡³ {request.end_date}",
        date_comparisons=date_comparisons,
        comparison_stats=stats,
        formatted_patent_results=formatted_patent_results,
        formatted_paper_results=formatted_paper_results,
        formatted_standard_results=formatted_standard_results,
        formatted_copyright_results=formatted_copyright_results  # æ·»åŠ è½¯è‘—æ ¼å¼åŒ–ç»“æœ

    )


# å¯åŠ¨æœåŠ¡å™¨
if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8001)
